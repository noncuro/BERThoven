{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP CW using BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7wcqPQtmXIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d -O files.zip\n",
        "!unzip files.zip\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfUlxtrvmgT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "2f962e91-a1ce-41bb-9e05-a05e154824b8"
      },
      "source": [
        "from daniel_lib import (tokenizer, import_file, pad, \n",
        "                        bert_model, get_tokenized, getDataLoader, \n",
        "                        removeOutliers, progress, get_sentence_embeddings, \n",
        "                        augment_dataset, BERThoven, check_accuracy, train_part, get_test_labels)\n",
        "from transformers import (AdamW,\n",
        "                          get_linear_schedule_with_warmup)\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import scipy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqb_sPmW2_YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_GPU = True\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnhFsNB4ec9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = import_file(\"train\")\n",
        "dev_df = import_file(\"dev\")\n",
        "test_df = import_file(\"test\")\n",
        "\n",
        "dataLoader_train = getDataLoader(train_df)\n",
        "dataLoader_dev = getDataLoader(dev_df)\n",
        "dataLoader_test = getDataLoader(test_df,test=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhcNsLBeSO_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_aug = augment_dataset(train_df, \n",
        "                            lambda score: score<-1,\n",
        "                            lambda score: score<-0.3, \n",
        "                            lambda score: score>0.55, \n",
        "                            lambda score: score>1, \n",
        "                            lambda score: score>1.3)\n",
        "dataLoader_train_aug = getDataLoader(train_df_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNfi-r_KUMYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(train_df2.shape)\n",
        "# plt.subplot(2,1,1)\n",
        "# train_df.scores.hist(bins=100)\n",
        "# plt.subplot(2,1,2)\n",
        "# train_df2.scores.hist(bins=100)\n",
        "# print(train_df.scores.mean(), train_df2.scores.mean())\n",
        "# print(train_df.scores.var(), train_df2.scores.var())\n",
        "\n",
        "# train_df[train_df.src == train_df.mt]\n",
        "# train_df[train_df.scores>0.5]\n",
        "# train_df.scores.hist(bins=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGEdwg18Jc6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_model = BERThoven(bert_model)\n",
        "# nlp_model.load_state_dict(torch.load(\"nlp_model.pt\"))\n",
        "check_accuracy(dataLoader_dev,nlp_model,device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY1_hfQOkjKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e99a6c27-6375-4625-be47-9c719ecd2c68"
      },
      "source": [
        "epochs = 10\n",
        "warmup_proportion = 0.1\n",
        "\n",
        "loss_function = F.l1_loss\n",
        "print_every=75\n",
        "\n",
        "steps_per_epoch = len(dataLoader_train_aug)\n",
        "training_steps = steps_per_epoch*epochs\n",
        "warmup_steps = int(training_steps*warmup_proportion)\n",
        "\n",
        "\n",
        "optimizer = AdamW(nlp_model.parameters(), lr=1e-6,eps=1e-9, correct_bias=False)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=training_steps)\n",
        "\n",
        "train_part(nlp_model, dataLoader_train_aug, optimizer,scheduler, \n",
        "           val_loader=dataLoader_dev, \n",
        "           epochs=epochs-2, \n",
        "           print_every=print_every, \n",
        "           loss_function=loss_function, \n",
        "           device=device)\n",
        "train_part(nlp_model, dataLoader_train_aug, optimizer, scheduler, \n",
        "           val_loader=dataLoader_dev, \n",
        "           epochs=2, \n",
        "           print_every=print_every, \n",
        "           loss_function=loss_function, \n",
        "           device=device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iterations per epoch:308\n",
            "\n",
            "Epoch: 0, Iteration 0, loss = 0.8352, avg_loss = 0.9918..........................................................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F77FuGA5Hoqq",
        "colab_type": "code",
        "outputId": "61307874-5410-4a5a-9d8a-f54d4624af0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "# check_accuracy(dataLoader_dev,nlp_model)\n",
        "\n",
        "# def writeScores(scores):\n",
        "#     fn = \"predictions.txt\"\n",
        "#     print(\"\")\n",
        "#     with open(fn, 'w') as output_file:\n",
        "#         for x in scores:\n",
        "#             output_file.write(f\"{x}\\n\")\n",
        "# p.hist()\n",
        "# dev_df.hist()\n",
        "labels=get_test_labels(dataLoader_test, nlp_model)\n",
        "p=pd.DataFrame(labels)#.hist()\n",
        "# p.head()\n",
        "p.hist()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f52b5a05b70>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIMtdkgpkuUtSgf4fnpi5y3hllN8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ1Loyz7-sfu",
        "colab_type": "text"
      },
      "source": [
        "### Try using only embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFcvY8OS_3PL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.lin_layer1 = nn.Linear(768*2, 1000)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        self.lin_layer2 = nn.Linear(1000, 1000)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        self.lin_layer3 = nn.Linear(1000, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        inp = torch.cat((x1,x2),1)\n",
        "        out1 = self.relu1(self.lin_layer1(inp))\n",
        "        out2 = self.relu2(self.lin_layer2(out1))\n",
        "        out3 = self.lin_layer3(out2)\n",
        "        return out3.squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuepURln_n-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_every=500\n",
        "def train_linear_model(model, dataloader, dataloader_val, optimizer, scheduler, epochs=1,max_grad_norm=1.0):\n",
        "\n",
        "    avg_loss = 1;\n",
        "    momentum = 0.01;\n",
        "\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        print(f\"Iterations per epoch:{len(dataloader)}\")\n",
        "        for t, ((x1,x2),y) in enumerate(dataloader):\n",
        "            model.train()  # put model to training mode\n",
        "            y = y.to(device=device, dtype=torch.float32)\n",
        "\n",
        "            scores = model(x1,x2)\n",
        "            \n",
        "            loss = F.mse_loss(scores, y)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "            l=loss.item()\n",
        "\n",
        "            avg_loss = l*momentum + avg_loss*(1-momentum)\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print()\n",
        "                print('Epoch: %d, Iteration %d, loss = %.4f, avg_loss = %.4f' % (e, t, l,avg_loss), end=\"\")\n",
        "            print(\".\",end=\"\")\n",
        "        print()\n",
        "        print(\"Avg loss %.3f\" % (avg_loss))\n",
        "        print(\"Checking accuracy on dev:\")\n",
        "        check_accuracy_linear(dataloader_val, model)\n",
        "        # print(\"Saving the model.\")\n",
        "        # torch.save(model.state_dict(), 'nlp_model.pt')\n",
        "\n",
        "def check_accuracy_linear(loader, model, max_sample_size=None):\n",
        "    model = model.to(device=device)\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    abs_error = 0\n",
        "    sqr_error = 0;\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (x1, x2), y in loader:\n",
        "            y = y.to(device=device, dtype=torch.float32)\n",
        "            scores = model.forward(x1,x2)\n",
        "            abs_error += (scores - y).abs().sum()\n",
        "            sqr_error += ((scores - y)**2).sum()\n",
        "            num_samples += scores.size(0)\n",
        "            if(max_sample_size!=None and num_samples>=num_samples):\n",
        "              break;\n",
        "        mse = sqr_error/num_samples\n",
        "        mae = abs_error/num_samples\n",
        "        print('Mean Absolute Error: %.3f, Mean Squared Error %.3f' % (mse, mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpURB-p4AtWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_embeddings = get_sentence_embeddings(train_df,bert_model)\n",
        "val_embeddings = get_sentence_embeddings(dev_df,bert_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRzPx4rGAq2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "warmup_proportion = 0.1\n",
        "\n",
        "steps_per_epoch = len(train_embeddings)\n",
        "training_steps = steps_per_epoch*epochs\n",
        "warmup_steps = int(training_steps*warmup_proportion)\n",
        "\n",
        "linear_model=LinearModel()\n",
        "\n",
        "optimizer = AdamW(linear_model.parameters(), lr=1e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=training_steps)\n",
        "\n",
        "train_linear_model(linear_model, train_embeddings,val_embeddings,optimizer,scheduler, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}